{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1c3443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages (4.7.0.68)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages (from opencv-python) (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361bf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7568da",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341706d",
   "metadata": {},
   "source": [
    "# Select which video to analize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54bab8",
   "metadata": {},
   "source": [
    "Replace INPUT_VIDEO_PATH var below with the name of video you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3048abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT_VIDEO_PATH = \"input_files/Traffic_Laramie_1.mp4\"\n",
    "INPUT_VIDEO_PATH = \"input_files/Traffic_Laramie_2.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6c1ac2",
   "metadata": {},
   "source": [
    "# Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db6755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONSECUTIVE_FRAMES = 2 # how manny frames will be compared to detect movement, less = more detailed detection, more computation needed\n",
    "MINIMAL_SIZE = 1600 # minimal object size, big enough to detect cars but avoid pedestrians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02491c28",
   "metadata": {},
   "source": [
    "# Define function that generates background model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a8da3a",
   "metadata": {},
   "source": [
    "The below function extracts the background from a video and returns a frame with all moving objects removed. To do this it obtains the median over 50 random frames selected from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c280a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # we will randomly select 50 frames for the calculating the median\n",
    "    frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    # we will store the frames in array\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        # set the frame id to read that particular frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "    # calculate the median\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e59a7",
   "metadata": {},
   "source": [
    "# Read video and instantiate video writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f3c59",
   "metadata": {},
   "source": [
    "Reads input video and extracts width, height and fps.\n",
    "then uses those parameters to instantiate a video writer that will be used to write the updated frames to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb2118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(INPUT_VIDEO_PATH)\n",
    "# get the video frame height and width\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "\n",
    "save_name = f\"output_files_task2/{INPUT_VIDEO_PATH.split('/')[-1]}\"\n",
    "# define codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(\n",
    "    save_name,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'), fps, \n",
    "    (frame_width, frame_height)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4a7ad",
   "metadata": {},
   "source": [
    "# Get background frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc49073",
   "metadata": {},
   "source": [
    "Applies background substraction technique to obtain a frame with moving objects removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc01271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the background model\n",
    "background = get_background(INPUT_VIDEO_PATH)\n",
    "# convert the background model to grayscale format\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b384b5",
   "metadata": {},
   "source": [
    "# Instantiate important utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17f1c2",
   "metadata": {},
   "source": [
    "**reset_counters()**: resets counters used for tracking car count  \n",
    "\n",
    "**find_closest_cord(cord, cords_set)**: finds closest point (and distance) betweenn given coordinates and cords_set. to do this compares euclidean distance between given coordinates and all points in cords_set.  \n",
    "\n",
    "**update_cord(current_cords, new_cors, cords_set)**: replaces old cords in cords_set with updated cords.  \n",
    "\n",
    "**draw_contours(contours, frame)**: draws bounding box on frame if object size is above MINIMAL_SIZE, also updates the car counter by tracking object's coordinate changes in cords_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00965347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "car_count = 0\n",
    "MAX_OBJECT_DISTANCE = 60\n",
    "cords_set = set()\n",
    "cords_to_delete_map = {}\n",
    "\n",
    "def reset_counters():\n",
    "    global car_count\n",
    "    global cords_set\n",
    "    car_count = 0\n",
    "    cords_set = set()\n",
    "\n",
    "def find_closest_cord(cord, cords_set):\n",
    "    closest_dist = 100000000\n",
    "    closest_cord = None\n",
    "    for c in cords_set:\n",
    "        point1 = np.array(cord)\n",
    "        point2 = np.array(c)\n",
    "        dist = np.linalg.norm(point1 - point2)\n",
    "        if(dist < closest_dist):\n",
    "            closest_dist = dist\n",
    "            closest_cord = c \n",
    "    return closest_cord, closest_dist\n",
    "\n",
    "def update_cord(current_cords, new_cors, cords_set):\n",
    "    cords_set.remove(current_cords)\n",
    "    cords_set.add(new_cors)\n",
    "\n",
    "def draw_contours(contours, frame):\n",
    "    global car_count\n",
    "    global cords_set\n",
    "    global cords_to_delete_map\n",
    "    cords_in_frame = set()\n",
    "    for contour in contours:\n",
    "        # continue through the loop if contour area is less than MINIMAL_SIZE...\n",
    "        # ... helps in removing noise detection\n",
    "        if cv2.contourArea(contour) < MINIMAL_SIZE:\n",
    "            continue\n",
    "        # get the xmin, ymin, width, and height coordinates from the contours\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        X_THRESHOLD = 150\n",
    "        if(y>280 and x<500 and ((x<X_THRESHOLD and y < 370) or (x>=X_THRESHOLD and y<400))):\n",
    "            ### object tracking starts here\n",
    "            cords_in_frame.add((x, y))\n",
    "            closest_cord, distance = find_closest_cord((x, y), cords_set)\n",
    "            if(distance <= MAX_OBJECT_DISTANCE):\n",
    "                update_cord(closest_cord, (x,y), cords_set)\n",
    "            else:\n",
    "                car_count += 1\n",
    "                cords_set.add((x, y))\n",
    "            ### object tracking ends here\n",
    "            # draw the bounding boxes\n",
    "            cv2.rectangle(frame, (x, y+2), (x+w, y+h), (0, 255, 0), 2)\n",
    "    ### remove old cords from cords_set\n",
    "    for cord in list(cords_set):\n",
    "        closest_cord, distance = find_closest_cord(cord, cords_in_frame)\n",
    "        if(distance > MAX_OBJECT_DISTANCE):\n",
    "            key = f\"{cord[0]}_{cord[1]}\"\n",
    "            if key not in cords_to_delete_map:\n",
    "                 cords_to_delete_map[key] = 0\n",
    "            cords_to_delete_map[key] +=1\n",
    "            if(cords_to_delete_map[key] > 3):\n",
    "                del cords_to_delete_map[key] \n",
    "                print(\"deleting cord from cords set(is out of frame): \", key)\n",
    "                cords_set.remove(cord)\n",
    "    ##### END old cord removal\n",
    "    cv2.putText(frame, f\"Car count: {str(car_count)} \", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "           1, (0, 255, 0), 2, cv2.LINE_AA) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d504038",
   "metadata": {},
   "source": [
    "# Create mask to remove all but main street"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69843c58",
   "metadata": {},
   "source": [
    "Below I will generate a frame to use it as a mask, all pixels will be 0 except for pixels that cover the main street area which I will set to 255, to apply it we will later perform an and operation between the mask and each video frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42221aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### mask only street we care about\n",
    "\n",
    "# a mask is the same size as our image, but has only two pixel\n",
    "# values, 0 and 255 -- pixels with a value of 0 (background) are\n",
    "# ignored in the original image while mask pixels with a value of\n",
    "# 255 (foreground) are allowed to be kept\n",
    "mask = np.zeros((frame_height, frame_width), dtype=\"uint8\")\n",
    "mask2 = np.zeros((frame_height, frame_width), dtype=\"uint8\")\n",
    "mask3 = np.zeros((frame_height, frame_width), dtype=\"uint8\")\n",
    "cv2.rectangle(mask, (0, 200), (80, 400), 255, -1)\n",
    "cv2.rectangle(mask2, (80, 200), (250, 420), 255, -1)\n",
    "cv2.rectangle(mask3, (250, 200), (500, 450), 255, -1)\n",
    "mask4 = cv2.bitwise_or(cv2.bitwise_or(mask, mask2), mask3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39dccc",
   "metadata": {},
   "source": [
    "# Main loop: iterate over frames and perform object detection and object tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2572eea",
   "metadata": {},
   "source": [
    "Loop over input video frames and do the following:  \n",
    "1- convert frames to grayscale for easier detection  \n",
    "2- find difference between current frame and background frame, ie: remove the background.  \n",
    "3- apply a threshold to convert all pixels to either 1 or 0 depending on difference with background.  \n",
    "4- Apply mask to only pay attention to objects on main street  \n",
    "5- Sum consecutive frames(with background removed): find contours around objects, represented as group of pixels clustered together with values above 0, only reason to do this is to reduce computation. finding the contour on a sequence of CONSECUTIVE_FRAMES frames is CONSECUTIVE_FRAMES times faster than doing it for individual frames.  \n",
    "6- Use OpenCV's findContours function to find contours for consecutive pixels that have non 0 values. We only find contours for the last pixel of each group of CONSECUTIVE_FRAMES, since need the previous frames of the group to calculate it(Later I still use the same contour for every pixel in the group)  \n",
    "7- append each frame with detected contours(if available) to a list of frames to later be written to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b832322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_counters()\n",
    "frame_diff_list = []\n",
    "frames_to_write = []\n",
    "frame_count = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame_count += 1\n",
    "        orig_frame = frame.copy()\n",
    "        # IMPORTANT STEP: convert the frame to grayscale first\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if frame_count % CONSECUTIVE_FRAMES == 0 or frame_count == 1:\n",
    "            frame_diff_list = []\n",
    "        # find the difference between current frame and base frame\n",
    "        frame_diff = cv2.absdiff(gray, background)\n",
    "        # thresholding to convert the frame to binary\n",
    "        ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # apply our mask\n",
    "        thres = cv2.bitwise_and(thres, thres, mask=mask4)\n",
    "            \n",
    "        \n",
    "        # dilate the frame a bit to get some more white area...\n",
    "        # ... makes the detection of contours a bit easier\n",
    "        dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "\n",
    "        # append the final result into the `frame_diff_list`\n",
    "        frame_diff_list.append(dilate_frame)\n",
    "        # if we have reached `CONSECUTIVE_FRAMES` number of frames\n",
    "        if len(frame_diff_list) == CONSECUTIVE_FRAMES:\n",
    "            # add all the frames in the `frame_diff_list`\n",
    "            sum_frames = sum(frame_diff_list)\n",
    "            \n",
    "            # find the contours around the white segmented areas\n",
    "            contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            frames_to_write.append((orig_frame, contours))\n",
    "        else:\n",
    "            # write intermediate frames to avoid frame skipping in output video? \n",
    "            frames_to_write.append((orig_frame, []))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40fa956",
   "metadata": {},
   "source": [
    "# write frames with the contours to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0cfa8",
   "metadata": {},
   "source": [
    "Loop over frames, contours list processed in previous step and for each frame:\n",
    "1) If don't have contours for this image, find the next contour in the list\n",
    "2) draw all contours as rectangles in the frame\n",
    "2) Write frame to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d6eda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting cord from cords set(is out of frame):  0_332\n",
      "deleting cord from cords set(is out of frame):  0_350\n",
      "deleting cord from cords set(is out of frame):  0_341\n",
      "deleting cord from cords set(is out of frame):  0_342\n"
     ]
    }
   ],
   "source": [
    "reset_counters()\n",
    "i=0\n",
    "for frame, contours in frames_to_write:\n",
    "    j=1\n",
    "    while(not contours and (i+j) <len(frames_to_write)):\n",
    "        contours = frames_to_write[i+j][1]\n",
    "        j+=1\n",
    "    i+=1\n",
    "    draw_contours(contours, frame)\n",
    "    out.write(frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1115de",
   "metadata": {},
   "source": [
    "# Calculate cars per minute and print total car count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f559a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars per minute:  2.271006813020439\n",
      "total car count:  4\n"
     ]
    }
   ],
   "source": [
    "total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration_sec = total_frame_count/fps\n",
    "number_of_minutes = duration_sec/60\n",
    "cars_per_minute = car_count / number_of_minutes\n",
    "print(\"cars per minute: \",cars_per_minute)\n",
    "print(\"total car count: \", car_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a25498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7613333333333334, 25, 2642)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_minutes, fps, total_frame_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3e9829",
   "metadata": {},
   "source": [
    "# Close video reader and writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f781604",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:UOL_sp_openCV] *",
   "language": "python",
   "name": "conda-env-UOL_sp_openCV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
