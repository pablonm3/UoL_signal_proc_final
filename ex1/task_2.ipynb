{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4521d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages (4.7.0.68)\r\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages (from opencv-python) (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf531c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d5f7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # we will randomly select 50 frames for the calculating the median\n",
    "    frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    # we will store the frames in array\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        # set the frame id to read that particular frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "    # calculate the median\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ae959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"input_files/Traffic_Laramie_2.mp4\"\n",
    "CONSECUTIVE_FRAMES = 2 # how manny frames will be compared to detect movement, less = more detailed detection, more computation needed\n",
    "MINIMAL_SIZE = 1800 # minimal object size, big enough to detect cars but avoid pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3bf5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(INPUT_VIDEO_PATH)\n",
    "# get the video frame height and width\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "\n",
    "save_name = f\"output_files_task2/{INPUT_VIDEO_PATH.split('/')[-1]}\"\n",
    "# define codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(\n",
    "    save_name,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'), fps, \n",
    "    (frame_width, frame_height)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09a3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the background model\n",
    "background = get_background(INPUT_VIDEO_PATH)\n",
    "# convert the background model to grayscale format\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "frame_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d407203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "car_count = 0\n",
    "MAX_OBJECT_DISTANCE = 60\n",
    "cords_set = set()\n",
    "cords_to_delete_map = {}\n",
    "\n",
    "def reset_counters():\n",
    "    global car_count\n",
    "    global cords_set\n",
    "    car_count = 0\n",
    "    cords_set = set()\n",
    "\n",
    "def find_closest_cord(cord, cords_set):\n",
    "    closest_dist = 100000000\n",
    "    closest_cord = None\n",
    "    for c in cords_set:\n",
    "        point1 = np.array(cord)\n",
    "        point2 = np.array(c)\n",
    "        dist = np.linalg.norm(point1 - point2)\n",
    "        if(dist < closest_dist):\n",
    "            closest_dist = dist\n",
    "            closest_cord = c \n",
    "    return closest_cord, closest_dist\n",
    "\n",
    "def update_cord(current_cords, new_cors, cords_set):\n",
    "    cords_set.remove(current_cords)\n",
    "    cords_set.add(new_cors)\n",
    "\n",
    "def draw_contours(contours, frame):\n",
    "    global car_count\n",
    "    global cords_set\n",
    "    global cords_to_delete_map\n",
    "    cords_in_frame = set()\n",
    "    for contour in contours:\n",
    "        # continue through the loop if contour area is less than MINIMAL_SIZE...\n",
    "        # ... helps in removing noise detection\n",
    "        if cv2.contourArea(contour) < MINIMAL_SIZE:\n",
    "            continue\n",
    "        # get the xmin, ymin, width, and height coordinates from the contours\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        X_THRESHOLD = 150\n",
    "        if(y>280 and x<500 and ((x<X_THRESHOLD and y < 370) or (x>=X_THRESHOLD and y<400))):\n",
    "            ### object tracking starts here\n",
    "            cords_in_frame.add((x, y))\n",
    "            closest_cord, distance = find_closest_cord((x, y), cords_set)\n",
    "            if(distance <= MAX_OBJECT_DISTANCE):\n",
    "                update_cord(closest_cord, (x,y), cords_set)\n",
    "            else:\n",
    "                car_count += 1\n",
    "                cords_set.add((x, y))\n",
    "            ### object tracking ends here\n",
    "            # car is going to city center\n",
    "            cv2.putText(frame, f\"x:{str(x)}, y:{str(y)} dist: {str(int(distance))}\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, (0, 255, 0), 2, cv2.LINE_AA) \n",
    "            # draw the bounding boxes\n",
    "            cv2.rectangle(frame, (x, y+2), (x+w, y+h), (0, 255, 0), 2)\n",
    "    ### remove old cords from cords_set\n",
    "    for cord in list(cords_set):\n",
    "        closest_cord, distance = find_closest_cord(cord, cords_in_frame)\n",
    "        if(distance > MAX_OBJECT_DISTANCE):\n",
    "            key = f\"{cord[0]}_{cord[1]}\"\n",
    "            if key not in cords_to_delete_map:\n",
    "                 cords_to_delete_map[key] = 0\n",
    "            cords_to_delete_map[key] +=1\n",
    "            if(cords_to_delete_map[key] > 3):\n",
    "                del cords_to_delete_map[key] \n",
    "                print(\"deleting cord from cords set(is out of frame): \", key)\n",
    "                cords_set.remove(cord)\n",
    "    ##### END old cord removal\n",
    "    cv2.putText(frame, f\"Car count: {str(car_count)} \", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "           1, (0, 255, 0), 2, cv2.LINE_AA) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d200f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting cord from cords set(is out of frame):  0_332\n",
      "deleting cord from cords set(is out of frame):  0_350\n",
      "deleting cord from cords set(is out of frame):  0_341\n",
      "deleting cord from cords set(is out of frame):  0_341\n"
     ]
    }
   ],
   "source": [
    "reset_counters()\n",
    "frame_diff_list = []\n",
    "frames_to_write = []\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame_count += 1\n",
    "        orig_frame = frame.copy()\n",
    "        # IMPORTANT STEP: convert the frame to grayscale first\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if frame_count % CONSECUTIVE_FRAMES == 0 or frame_count == 1:\n",
    "            frame_diff_list = []\n",
    "        # find the difference between current frame and base frame\n",
    "        frame_diff = cv2.absdiff(gray, background)\n",
    "        # thresholding to convert the frame to binary\n",
    "        ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        \n",
    "        ### mask only street we care about\n",
    "\n",
    "        # a mask is the same size as our image, but has only two pixel\n",
    "        # values, 0 and 255 -- pixels with a value of 0 (background) are\n",
    "        # ignored in the original image while mask pixels with a value of\n",
    "        # 255 (foreground) are allowed to be kept\n",
    "        mask = np.zeros(thres.shape[:2], dtype=\"uint8\")\n",
    "        mask2 = np.zeros(thres.shape[:2], dtype=\"uint8\")\n",
    "        mask3 = np.zeros(thres.shape[:2], dtype=\"uint8\")\n",
    "        cv2.rectangle(mask, (0, 200), (80, 400), 255, -1)\n",
    "        cv2.rectangle(mask2, (80, 200), (250, 420), 255, -1)\n",
    "        cv2.rectangle(mask3, (250, 200), (500, 450), 255, -1)\n",
    "        mask4 = cv2.bitwise_or(cv2.bitwise_or(mask, mask2), mask3)\n",
    "\n",
    "        \n",
    "        # apply our mask -- notice how only the person in the image is\n",
    "        # cropped out\n",
    "        thres = cv2.bitwise_and(thres, thres, mask=mask4)\n",
    "        \n",
    "        \n",
    "        ### end of masking\n",
    "        \n",
    "        \n",
    "        # dilate the frame a bit to get some more white area...\n",
    "        # ... makes the detection of contours a bit easier\n",
    "        dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "\n",
    "        # append the final result into the `frame_diff_list`\n",
    "        frame_diff_list.append(dilate_frame)\n",
    "        # if we have reached `CONSECUTIVE_FRAMES` number of frames\n",
    "        if len(frame_diff_list) == CONSECUTIVE_FRAMES:\n",
    "            # add all the frames in the `frame_diff_list`\n",
    "            sum_frames = sum(frame_diff_list)\n",
    "            \n",
    "            # find the contours around the white segmented areas\n",
    "            contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            \n",
    "            \n",
    "            frames_to_write.append((orig_frame, contours))\n",
    "            draw_contours(contours, frame)\n",
    "            cv2.imshow('Detected Objects', frame)\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # write intermediate frames to avoid frame skipping in output video? \n",
    "            frames_to_write.append((orig_frame, []))\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264b7a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars per minute:  2.271006813020439\n",
      "total car count:  4\n"
     ]
    }
   ],
   "source": [
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration_sec = frame_count/fps\n",
    "number_of_minutes = duration_sec/60\n",
    "cars_per_minute = car_count / number_of_minutes\n",
    "print(\"cars per minute: \",cars_per_minute)\n",
    "print(\"total car count: \", car_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting cord from cords set(is out of frame):  0_332\n",
      "deleting cord from cords set(is out of frame):  0_350\n",
      "deleting cord from cords set(is out of frame):  0_341\n"
     ]
    }
   ],
   "source": [
    "reset_counters()\n",
    "i=0\n",
    "for frame, contours in frames_to_write:\n",
    "    j=1\n",
    "    while(not contours and (i+j) <len(frames_to_write)):\n",
    "        contours = frames_to_write[i+j][1]\n",
    "        j+=1\n",
    "    i+=1\n",
    "    draw_contours(contours, frame)\n",
    "    out.write(frame)\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:UOL_sp_openCV] *",
   "language": "python",
   "name": "conda-env-UOL_sp_openCV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
