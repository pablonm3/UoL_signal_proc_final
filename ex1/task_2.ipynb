{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45dee4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages (4.7.0.68)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages (from opencv-python) (1.24.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c95187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2fd43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_background(file_path):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # we will randomly select 50 frames for the calculating the median\n",
    "    frame_indices = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=50)\n",
    "    # we will store the frames in array\n",
    "    frames = []\n",
    "    for idx in frame_indices:\n",
    "        # set the frame id to read that particular frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "    # calculate the median\n",
    "    median_frame = np.median(frames, axis=0).astype(np.uint8)\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c29ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VIDEO_PATH = \"input_files/Traffic_Laramie_2.mp4\"\n",
    "CONSECUTIVE_FRAMES = 2 # how manny frames will be compared to detect movement, less = more detailed detection, more computation needed\n",
    "MINIMAL_SIZE = 2000 # minimal object size, big enough to detect cars but avoid pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4db006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(INPUT_VIDEO_PATH)\n",
    "# get the video frame height and width\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(5))\n",
    "\n",
    "save_name = f\"output_files_task2/{INPUT_VIDEO_PATH.split('/')[-1]}\"\n",
    "# define codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(\n",
    "    save_name,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'), fps, \n",
    "    (frame_width, frame_height)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d38cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the background model\n",
    "background = get_background(INPUT_VIDEO_PATH)\n",
    "# convert the background model to grayscale format\n",
    "background = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
    "frame_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c91a4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(contours, frame):\n",
    "    for contour in contours:\n",
    "        # continue through the loop if contour area is less than MINIMAL_SIZE...\n",
    "        # ... helps in removing noise detection\n",
    "        if cv2.contourArea(contour) < MINIMAL_SIZE:\n",
    "            continue\n",
    "        # get the xmin, ymin, width, and height coordinates from the contours\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        if(x <500 and y>280 and y<370):\n",
    "            # car is going to city center\n",
    "            cv2.putText(frame, f\"x:{str(x)}, y:{str(y)} \", (x, y), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                       1, (0, 255, 0), 2, cv2.LINE_AA) \n",
    "            # draw the bounding boxes\n",
    "            cv2.rectangle(frame, (x, y+2), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9153cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_diff_list = []\n",
    "frames_to_write = []\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame_count += 1\n",
    "        orig_frame = frame.copy()\n",
    "        # IMPORTANT STEP: convert the frame to grayscale first\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        if frame_count % CONSECUTIVE_FRAMES == 0 or frame_count == 1:\n",
    "            frame_diff_list = []\n",
    "        # find the difference between current frame and base frame\n",
    "        frame_diff = cv2.absdiff(gray, background)\n",
    "        # thresholding to convert the frame to binary\n",
    "        ret, thres = cv2.threshold(frame_diff, 50, 255, cv2.THRESH_BINARY)\n",
    "        # dilate the frame a bit to get some more white area...\n",
    "        # ... makes the detection of contours a bit easier\n",
    "        dilate_frame = cv2.dilate(thres, None, iterations=2)\n",
    "        # append the final result into the `frame_diff_list`\n",
    "        frame_diff_list.append(dilate_frame)\n",
    "        # if we have reached `CONSECUTIVE_FRAMES` number of frames\n",
    "        if len(frame_diff_list) == CONSECUTIVE_FRAMES:\n",
    "            # add all the frames in the `frame_diff_list`\n",
    "            sum_frames = sum(frame_diff_list)\n",
    "            # find the contours around the white segmented areas\n",
    "            contours, hierarchy = cv2.findContours(sum_frames, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            frames_to_write.append((orig_frame, contours))\n",
    "            draw_contours(contours, orig_frame)\n",
    "            cv2.imshow('Detected Objects', orig_frame)\n",
    "            if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # write intermediate frames to avoid frame skipping in output video? \n",
    "            frames_to_write.append((orig_frame, []))\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b6a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for frame, contours in frames_to_write:\n",
    "    j=1\n",
    "    while(not contours and (i+j) <len(frames_to_write)):\n",
    "        contours = frames_to_write[i+j][1]\n",
    "        j+=1\n",
    "    i+=1\n",
    "    draw_contours(contours, frame)\n",
    "    out.write(frame)\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:UOL_sp_openCV] *",
   "language": "python",
   "name": "conda-env-UOL_sp_openCV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
