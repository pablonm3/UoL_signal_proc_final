{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection using Python and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this exercise we are going to use Python and OpenCV to do real-time face detection from a live stream via our webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Very important: you need to run the code in your local machine for using the webcam.**\n",
    "\n",
    "**Exercise 1.1**: Download (or copy) this Jupyter notebook into your local machine.\n",
    "\n",
    "**Exercise 1.2**: Install in your local machine (if you haven't done it yet) OpenCV library\n",
    "\n",
    "            pip install opencv-python\n",
    "\n",
    "**Exercise 1.3**: Run and study the code *Face detection in Python using OpenCV*. \n",
    "\n",
    "**Exercise 1.4**: Cat face detection using OpenCV!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.68-cp37-abi3-macosx_10_13_x86_64.whl (51.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.17.0\n",
      "  Downloading numpy-1.24.2-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.24.2 opencv-python-4.7.0.68\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3. Face detection in Python using OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we are going to use the Haar Cascade Classifiers method for face detection. \n",
    "\n",
    "The Haar Cascade Classifiers method is basically a machine learning based approach where a cascade function is trained from a lot of images. The training data is stored in huge individual .xml files with a lot of feature sets. Each xml corresponds to a very specific type of use case.\n",
    "\n",
    "In this application, we are going to use a the file 'haarcascade_frontalface_default.xml' for face detection as our pre-trained model. You downloaded this file when you installed 'opencv-python'. If needed, you can download it again from the from the opencv github repository https://github.com/opencv/opencv/tree/master/data/haarcascades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages/cv2/data/haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "# Face detection in Python using OpenCV\n",
    "\n",
    "# Import the OpenCV library\n",
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "# load our classifier.\n",
    "# Make sure that the path to the xml file is correct.\n",
    "cascade_path = pathlib.Path(cv2.__file__).parent.absolute() / \"data/haarcascade_frontalface_default.xml\"\n",
    "print(cascade_path)\n",
    "face_cascade = cv2.CascadeClassifier(str(cascade_path))\n",
    "\n",
    "# We use VideoCapture function to create the video capture object\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# We start an infinite loop and keep reading frames from the webcam until we press 'q'\n",
    "while True:\n",
    "    ret, image = video.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "    \n",
    "    # For this face detection classifier to work, we need to convert the frame into greyscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # The gray image has been stored as a multidimensional numpy array. \n",
    "    # print(type(gray_image))\n",
    "\n",
    "    \n",
    "    # The detectMultiScale method is the one that will perform the face detection for us.\n",
    "    # scaleFactor specifies the factor by which the image is scaled down.\n",
    "    # For example, a scaleFactor of 1.10 will require less computation than a scaleFactor of 1.05.\n",
    "    # minNeighbors is a threshold value that specifies the minimum number of times a region has to be determined as a face.\n",
    "    # Experiment with different minNeighbors values!\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.10, minNeighbors=5)\n",
    "\n",
    "    # Print the dimensions and positions of the rectangles containing the faces\n",
    "    # print(faces)\n",
    "    \n",
    "    # We now draw a rectangle in the position (x,y), dimensions (w,h)\n",
    "    # in green color (0, 255, 0) with the border thickness = 1.\n",
    "    for(x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imshow('Face Detector', image)\n",
    "    \n",
    "    # Press 'q' to 'quit'\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4. Cat face detection in Python using OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have a cat? There are also a bunch of other models from the opencv github repository https://github.com/opencv/opencv/tree/master/data/haarcascades that you might want to try out, such as the cat face detection (haarcascade_frontalcatface.xml)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This lab is based on https://github.com/arindomjit/Face_Detector by Arindomjit Bhattacharjee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pablo/opt/anaconda3/envs/UOL_sp_openCV/lib/python3.9/site-packages/cv2/data/haarcascade_frontalcatface.xml\n"
     ]
    }
   ],
   "source": [
    "# Face detection in Python using OpenCV\n",
    "\n",
    "# Import the OpenCV library\n",
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "# load our classifier.\n",
    "# Make sure that the path to the xml file is correct.\n",
    "cascade_path = pathlib.Path(cv2.__file__).parent.absolute() / \"data/haarcascade_frontalcatface.xml\"\n",
    "print(cascade_path)\n",
    "face_cascade = cv2.CascadeClassifier(str(cascade_path))\n",
    "\n",
    "# We use VideoCapture function to create the video capture object\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "# We start an infinite loop and keep reading frames from the webcam until we press 'q'\n",
    "while True:\n",
    "    ret, image = video.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "    \n",
    "    # For this face detection classifier to work, we need to convert the frame into greyscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # The gray image has been stored as a multidimensional numpy array. \n",
    "    # print(type(gray_image))\n",
    "\n",
    "    \n",
    "    # The detectMultiScale method is the one that will perform the face detection for us.\n",
    "    # scaleFactor specifies the factor by which the image is scaled down.\n",
    "    # For example, a scaleFactor of 1.10 will require less computation than a scaleFactor of 1.05.\n",
    "    # minNeighbors is a threshold value that specifies the minimum number of times a region has to be determined as a face.\n",
    "    # Experiment with different minNeighbors values!\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.10, minNeighbors=5)\n",
    "\n",
    "    # Print the dimensions and positions of the rectangles containing the faces\n",
    "    # print(faces)\n",
    "    \n",
    "    # We now draw a rectangle in the position (x,y), dimensions (w,h)\n",
    "    # in green color (0, 255, 0) with the border thickness = 1.\n",
    "    for(x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x,y), (x+w, y+h), (0, 255, 0), 1)\n",
    "        \n",
    "    cv2.imshow('Face Detector', image)\n",
    "    \n",
    "    # Press 'q' to 'quit'\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:UOL_sp_openCV] *",
   "language": "python",
   "name": "conda-env-UOL_sp_openCV-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
